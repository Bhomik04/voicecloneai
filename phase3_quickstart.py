"""
Phase 3 Quick Start - Dataset & Fine-Tuning Guide
==================================================

This script helps you get started with Phase 3:
1. Download datasets from Kaggle/HuggingFace
2. Prepare training data
3. Fine-tune your model

Run: python phase3_quickstart.py
"""

import os
import sys
from pathlib import Path

# Set environment for D: drive
os.environ['HF_HOME'] = 'D:\\voice cloning\\models_cache\\huggingface'
os.environ['TORCH_HOME'] = 'D:\\voice cloning\\models_cache\\torch'


def print_header():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸ“‚ PHASE 3: DATASETS & FINE-TUNING                     â•‘
â•‘           Quick Start Guide                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


def check_kaggle_setup():
    """Check if Kaggle API is configured"""
    print("\nğŸ” Checking Kaggle API setup...")
    
    kaggle_json = Path.home() / ".kaggle" / "kaggle.json"
    
    if kaggle_json.exists():
        print("   âœ… Kaggle API configured")
        return True
    else:
        print("   âš ï¸ Kaggle API not configured")
        print("""
   ğŸ“‹ To set up Kaggle API:
   1. Go to: https://www.kaggle.com/settings
   2. Scroll to "API" section
   3. Click "Create New Token"
   4. Save kaggle.json to: C:\\Users\\<username>\\.kaggle\\kaggle.json
""")
        return False


def show_recommended_datasets():
    """Show recommended datasets for different use cases"""
    print("\nğŸ“Š RECOMMENDED DATASETS BY USE CASE:")
    print("=" * 60)
    
    print("""
ğŸ¯ FOR QUICK EXPERIMENTS (< 2GB):
   â€¢ cmu_arctic (1.2 GB, 7 speakers, 7 hours)
     Command: manager.download('cmu_arctic')

ğŸ¯ FOR ENGLISH VOICE CLONING (2-10 GB):
   â€¢ ljspeech (2.6 GB, 1 speaker, 24 hours)
     Best for: Single-speaker fine-tuning
     Command: manager.download('ljspeech')
   
   â€¢ libritts_clean (5.6 GB, 251 speakers, 100 hours)
     Best for: Multi-speaker voice cloning
     Command: manager.download('libritts_clean')

ğŸ¯ FOR HINDI VOICE CLONING:
   â€¢ hindi_tts_kaggle (7.0 GB, 10 speakers, 50 hours)
     Best for: Hindi TTS fine-tuning
     Command: manager.download('hindi_tts_kaggle')
   
   â€¢ common_voice_hi (3.0 GB, 5000 speakers, 100 hours)
     Best for: Hindi ASR/TTS
     Command: manager.download('common_voice_hi')

ğŸ¯ FOR PRODUCTION (10+ GB):
   â€¢ vctk (10.9 GB, 110 speakers, 44 hours)
     Best for: Multi-accent English
     Command: manager.download('vctk')
""")


def interactive_download():
    """Interactive dataset download"""
    from dataset_manager import DatasetManager, DATASETS_CATALOG
    
    print("\nğŸ“¥ DATASET DOWNLOAD")
    print("=" * 60)
    
    manager = DatasetManager()
    
    print("\nğŸ“‹ Available datasets:")
    for i, (name, info) in enumerate(DATASETS_CATALOG.items(), 1):
        status = "âœ…" if name in manager.downloaded_datasets else "â¬œ"
        print(f"   {i}. {status} {name} ({info.size_gb} GB, {info.languages})")
    
    print("\n   0. Skip download")
    
    choice = input("\nğŸ‘‰ Enter number to download (or 0 to skip): ").strip()
    
    if choice == "0":
        return
    
    try:
        idx = int(choice) - 1
        dataset_name = list(DATASETS_CATALOG.keys())[idx]
        
        print(f"\nğŸ“¥ Downloading {dataset_name}...")
        manager.download(dataset_name)
        
    except (ValueError, IndexError):
        print("âŒ Invalid choice")


def prepare_training_data():
    """Guide for preparing training data"""
    print("\nğŸ“¦ PREPARE TRAINING DATA")
    print("=" * 60)
    
    print("""
To prepare downloaded datasets for training:

```python
from prepare_dataset import DatasetPreparer

# Initialize preparer
preparer = DatasetPreparer("D:/voice cloning/training_data")

# Add dataset(s) - choose based on what you downloaded:

# Option 1: LJSpeech (single speaker)
preparer.add_ljspeech("D:/voice cloning/datasets/ljspeech")

# Option 2: VCTK (multi-speaker)
preparer.add_vctk("D:/voice cloning/datasets/vctk", max_speakers=20)

# Option 3: Your own recordings
preparer.add_custom_folder(
    audio_dir="your_audio_folder",
    transcripts_file="your_transcripts.csv",  # filename|text
    speaker_id="my_voice",
    language="en"  # or "hi" for Hindi
)

# Prepare final dataset
train_meta, val_meta = preparer.prepare(split_ratio=0.95)
```

Output will be in: D:/voice cloning/training_data/
   â”œâ”€â”€ wavs/          (resampled audio files)
   â”œâ”€â”€ metadata.csv   (all samples)
   â”œâ”€â”€ metadata_train.csv
   â”œâ”€â”€ metadata_val.csv
   â””â”€â”€ speakers.json
""")


def show_fine_tuning_guide():
    """Guide for fine-tuning"""
    print("\nğŸ”§ FINE-TUNING GUIDE")
    print("=" * 60)
    
    print("""
After preparing your dataset, run fine-tuning:

```bash
# Basic fine-tuning (50 epochs)
python fine_tuner.py --dataset "D:/voice cloning/training_data" --epochs 50

# With custom settings
python fine_tuner.py \\
    --dataset "D:/voice cloning/training_data" \\
    --epochs 100 \\
    --batch-size 1 \\
    --lr 1e-5 \\
    --output "D:/voice cloning/fine_tuned_models"
```

âš¡ OPTIMIZATION FOR T2000 4GB VRAM:
   â€¢ Batch size: 1 (automatically set)
   â€¢ FP16 enabled (saves 50% VRAM)
   â€¢ Gradient checkpointing enabled
   â€¢ Gradient accumulation: 4 steps

ğŸ“Š Expected Training Time:
   â€¢ 1000 samples, 50 epochs: ~2-4 hours
   â€¢ 5000 samples, 50 epochs: ~8-12 hours
   â€¢ 10000 samples, 50 epochs: ~20-30 hours

ğŸ’¾ Checkpoints saved to:
   D:/voice cloning/fine_tuned_models/
   â”œâ”€â”€ epoch_10/
   â”œâ”€â”€ epoch_20/
   â”œâ”€â”€ ...
   â”œâ”€â”€ best_model/
   â””â”€â”€ final/
""")


def show_custom_recording_guide():
    """Guide for recording your own voice"""
    print("\nğŸ¤ RECORD YOUR OWN VOICE DATASET")
    print("=" * 60)
    
    print("""
For best voice cloning results, record your own voice:

ğŸ“‹ RECORDING REQUIREMENTS:
   â€¢ 30-60 minutes of audio (minimum 100 samples)
   â€¢ Clear, quiet environment
   â€¢ Consistent microphone distance
   â€¢ Various emotions and tones
   â€¢ Both English and Hindi (if bilingual)

ğŸ“ TRANSCRIPT FORMAT (transcripts.csv):
   filename|text
   sample_001|Hello, my name is Bhomik.
   sample_002|This is a test recording.
   sample_003|à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤®à¥‡à¤°à¤¾ à¤¨à¤¾à¤® à¤­à¥‹à¤®à¤¿à¤• à¤¹à¥ˆà¥¤
   ...

ğŸ“ FOLDER STRUCTURE:
   my_recordings/
   â”œâ”€â”€ sample_001.wav
   â”œâ”€â”€ sample_002.wav
   â”œâ”€â”€ sample_003.wav
   â””â”€â”€ transcripts.csv

ğŸ™ï¸ RECOMMENDED RECORDING SCRIPTS:

ENGLISH (30 sentences):
1. "Hello, my name is [name]. Nice to meet you."
2. "The weather today is absolutely beautiful."
3. "I can't believe how amazing this technology is!"
4. "Let me tell you a story about my childhood."
5. "Please speak slowly and clearly."
... (continue with various emotions)

HINDI (30 sentences):
1. "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤®à¥‡à¤°à¤¾ à¤¨à¤¾à¤® [à¤¨à¤¾à¤®] à¤¹à¥ˆà¥¤"
2. "à¤†à¤œ à¤•à¤¾ à¤®à¥Œà¤¸à¤® à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¤¾ à¤¹à¥ˆà¥¤"
3. "à¤¯à¤¹ à¤¤à¤•à¤¨à¥€à¤• à¤•à¤¿à¤¤à¤¨à¥€ à¤…à¤¦à¥à¤­à¥à¤¤ à¤¹à¥ˆ!"
4. "à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥‹ à¤…à¤ªà¤¨à¥‡ à¤¬à¤šà¤ªà¤¨ à¤•à¥€ à¤•à¤¹à¤¾à¤¨à¥€ à¤¸à¥à¤¨à¤¾à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤"
5. "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤§à¥€à¤°à¥‡ à¤”à¤° à¤¸à¥à¤ªà¤·à¥à¤Ÿ à¤¬à¥‹à¤²à¥‡à¤‚à¥¤"
... (continue with various emotions)

ğŸ’¡ TIPS:
   â€¢ Record in WAV format (44.1kHz or 22.05kHz)
   â€¢ Each sample: 5-15 seconds
   â€¢ Include: neutral, excited, calm, dramatic tones
   â€¢ Avoid background noise and echo
""")


def main():
    print_header()
    
    while True:
        print("\nğŸ“‹ PHASE 3 OPTIONS:")
        print("   1. Check Kaggle API setup")
        print("   2. View recommended datasets")
        print("   3. Download a dataset")
        print("   4. View data preparation guide")
        print("   5. View fine-tuning guide")
        print("   6. View custom recording guide")
        print("   7. Exit")
        
        choice = input("\nğŸ‘‰ Enter choice (1-7): ").strip()
        
        if choice == "1":
            check_kaggle_setup()
        elif choice == "2":
            show_recommended_datasets()
        elif choice == "3":
            try:
                interactive_download()
            except Exception as e:
                print(f"âŒ Error: {e}")
                print("   Make sure Kaggle API is configured for Kaggle datasets")
        elif choice == "4":
            prepare_training_data()
        elif choice == "5":
            show_fine_tuning_guide()
        elif choice == "6":
            show_custom_recording_guide()
        elif choice == "7":
            print("\nğŸ‘‹ Goodbye! Happy voice cloning!")
            break
        else:
            print("âŒ Invalid choice. Please enter 1-7.")


if __name__ == "__main__":
    main()
